{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconstruction of 3D Genome Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all biological processes can be explained by genomic variations alone.\n",
    "Epigenetics is the study of changes in gene activity that do not involve alterations in the DNA sequence itself.\n",
    "\n",
    "One aspect of epigenetics is the role of chromosome folding in the nucleus which has different biological impacts, most importantly on [transcriptional regulation](https://en.wikipedia.org/wiki/Transcriptional_regulation) (the disruption of which can lead to disease).\n",
    "The human genome is very long when stretched end-to-end, yet it forms a dense packing in the nucleus, and hierarchical structures such as ([interphase](https://en.wikipedia.org/wiki/Interphase)) chromosome territories, A/B compartments, topologically associating domains (TADs), and chromatin loops can be observed.\n",
    "\n",
    "> A/B compartment-associated regions are on the multi-Mb scale and correlate with either open and expression-active chromatin (\"A\" compartments) or closed and expression-inactive chromatin (\"B\" compartments).\n",
    "> A compartments tend to be gene-rich, have high GC-content, contain histone markers for active transcription, and usually displace the interior of the nucleus.\n",
    "> B compartments, on the other hand, tend to be gene-poor, compact, contain histone markers for gene silencing, and lie on the nuclear periphery.\n",
    "\n",
    "> A TAD is a self-interacting genomic region, typically on the sub-Mb scale.\n",
    "> DNA sequences within a TAD physically interact with each other more frequently than with sequences outside the TAD.\n",
    "\n",
    "We can study chromosome structure through chromosome conformation capture techniques such as [Hi-C](https://en.wikipedia.org/wiki/Hi-C_(genomic_analysis_technique)).\n",
    "The Hi-C protocol is depicted in the following figure.\n",
    "\n",
    "<img src=\"images/hic_protocol.jpeg\" width=800 />\n",
    "\n",
    "First, the DNA is cross-linked to fix nearby regions.\n",
    "Then the DNA is cut with a restriction enzyme and both ends are filled and labeled with biotin.\n",
    "Note the use of a type III restriction enzyme that interacts with two separate DNA sequences in inversely repeated head-to-head orientations for efficient cleavage and later ligation.\n",
    "Hi-C uses high-throughput sequencing to find the nucleotide sequence of fragments and uses paired-end sequencing, which retrieves a short sequence from each end of each ligated fragment.\n",
    "As such, for a given ligated fragment, the two sequences obtained should represent two different restriction fragments that were ligated together in the proximity based ligation step.\n",
    "The pair of sequences are individually aligned to the genome, thus determining the fragments involved in that ligation event.\n",
    "Hence, all possible pairwise interactions between fragments are tested.\n",
    "Hi-C is capable of capturing the interactions between loci across chromosomes, i.e., genome-wide.\n",
    "\n",
    "The interactions (i.e., contacts) are then accumulated into a single matrix&nbsp;&mdash;&nbsp;the contact matrix $\\mathbf{C}$.\n",
    "Typically, these are intra-chromosomal contact matrices, representing interactions within a single chromosome.\n",
    "Each row and column of the matrix represents a small region in a chromosome.\n",
    "The size of these regions is referred to as \"resolution\" and is constant for the whole contact matrix.\n",
    "\n",
    "<img src=\"images/contact_matrix.png\" width=600 />\n",
    "\n",
    "The number of contacts is inversely related to the (Euclidean) distance in three-dimensional space, since neighboring regions are more likely to interact.\n",
    "Therefore, we can convert the contact matrix $\\mathbf{C}$ into a a proxy of the Euclidean distance matrix (EDM) $\\mathbf{D}$ using a conversion factor $\\alpha$:\n",
    "\n",
    "$$\n",
    "D_{i,j} = \\frac{1}{C^{\\alpha}_{i,j}}.\n",
    "$$\n",
    "\n",
    "An important point is that Hi-C and similar protocols cannot reveal all possible interacting regions, i.e., there are many zero entries in the contact matrix.\n",
    "We express this phenomenon with an observation operator $\\mathcal{P}_{\\mathbf{\\Omega}}$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{P}_{\\mathbf{\\Omega}}(\\mathbf{C})_{i,j} = \n",
    "\\begin{cases}\n",
    "    C_{i,j}, & (i,j) \\in \\mathbf{\\Omega},\\\\\n",
    "    0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix and Euclidean Distance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the three-dimensional structure of a chromosome given a set of observed interactions, we need to find the best point set representation&nbsp;&mdash;&nbsp;the positions of the DNA in space&nbsp;&mdash;&nbsp;given the set of observed interactions.\n",
    "This problem is called [multidimensional scaling](https://en.wikipedia.org/wiki/Multidimensional_scaling) (MDS).\n",
    "\n",
    "We define a set of $n$ points in $d$-dimensional space as a $d\\times n$ coordinate matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{P} = \n",
    "\\begin{bmatrix}\n",
    "    \\mathbf{p}_1 &\n",
    "    \\mathbf{p}_2 &\n",
    "    \\cdots &\n",
    "    \\mathbf{p}_i &\n",
    "    \\cdots &\n",
    "    \\mathbf{p}_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{p}_i \\in \\mathbb{R}^{d}$ is the coordinate vector of $i$-th point in $d$-dimensional space.\n",
    "\n",
    "The Gram matrix $\\mathbf{G} \\in \\mathbb{R}^{n\\times n}$ of a coordinate matrix $\\mathbf{P}$ is defined as the inner product of all possible pairs of coordinate vectors:\n",
    "\n",
    "$$\n",
    "{G}_{i,j} \\coloneqq \\langle \\mathbf{p}_i, \\mathbf{p}_j \\rangle = \\mathbf{p}_i^T \\mathbf{p}_j.\n",
    "$$\n",
    "\n",
    "Interestingly the EDM $\\mathbf{D}$ can be computed from the Gram matrix $\\mathbf{G}$ as\n",
    "\n",
    "$$\n",
    "\\mathbf{D} = \\text{diag}(\\mathbf{G})\\mathbf{1}^T + \\mathbf{1}\\text{diag}(\\mathbf{G})^T - 2\\mathbf{G},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{1}$ is the $n$-dimensional ones vector, and $\\text{diag}(\\mathbf{\\cdot})$ is the operation that takes the diagonal of a matrix and creates a vector out of it.\n",
    "\n",
    "Note that the EDM does not contain information about the absolute position and the orientation of the points in the coordinate matrix.\n",
    "In other words, the EDM in invariant to rigid transformations (i.e., translation and rotation), including reflections, since these do not change the distances between points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Gram matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function named `coord2gram` that computes the Gram matrix from a coordinate matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def coord2gram(coord_mat: npt.NDArray[Any]) -> npt.NDArray[Any]:\n",
    "    \"\"\"Convert a matrix of coordinates to a Gram matrix.\"\"\"\n",
    "    return coord_mat.T @ coord_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = np.array([1, 0, 2])\n",
    "p_2 = np.array([1, 1, 2])\n",
    "coord_mat = np.stack((p_1, p_2)).T\n",
    "gram_mat = coord2gram(coord_mat=coord_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ EDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function named `gram2edm` that computes the EDM from a Gram matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram2edm(gram_mat: npt.NDArray[Any]) -> npt.NDArray[Any]:\n",
    "    \"\"\"Convert a Gram matrix to an Euclidean distance matrix.\"\"\"\n",
    "    diag_vec = np.diag(gram_mat).reshape((-1, 1))\n",
    "    n, _ = gram_mat.shape\n",
    "    ones_vec = np.ones(shape=(n, 1))\n",
    "    ed_mat = diag_vec @ ones_vec.T + ones_vec * diag_vec.T - 2 * gram_mat\n",
    "    return ed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = np.array([1, 0, 2])\n",
    "p_2 = np.array([1, 1, 2])\n",
    "coord_mat = np.stack((p_1, p_2)).T\n",
    "gram_mat = coord2gram(coord_mat=coord_mat)\n",
    "ed_mat = gram2edm(gram_mat=gram_mat)\n",
    "print(ed_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving a Simulated Multi-Dimensional Scaling Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we will try to solve an MDS problem using simulated data.\n",
    "For this task, we will use a spiral-shaped string of beads (i.e., points) as a model of a chromosome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ A spiral-shaped string of beads as chromosome proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the provided spiral parameters.\n",
    "Compute the `x`, `y`, and `z` components of all beads and create a coordinate matrix `coord_mat` from them.\n",
    "\n",
    "> Hint: exploit the conversion from a cylindrical to a cartesian coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIRAL_N_ROTATIONS = 4\n",
    "SPIRAL_N_POINTS = 100\n",
    "SPIRAL_HEIGHT = 1\n",
    "SPIRAL_RADIUS = 0.5\n",
    "\n",
    "spiral_end = SPIRAL_N_ROTATIONS * 2 * np.pi\n",
    "bead_indexes = np.arange(SPIRAL_N_POINTS)\n",
    "\n",
    "x = SPIRAL_RADIUS * np.cos((bead_indexes / SPIRAL_N_POINTS) * spiral_end)\n",
    "y = SPIRAL_RADIUS * np.sin((bead_indexes / SPIRAL_N_POINTS) * spiral_end)\n",
    "z = (bead_indexes / SPIRAL_N_POINTS) * SPIRAL_HEIGHT\n",
    "\n",
    "coord_mat = np.stack([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def scatter_3d(coord_mat: npt.NDArray[Any]) -> None:\n",
    "    \"\"\"Create a 3D scatter plot of the coordinates.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(*coord_mat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_3d(coord_mat=coord_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Simulation of a Hi-C protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Hi-C and similar protocols cannot reveal all possible interacting regions, i.e., there are many zero entries in the contact matrix.\n",
    "We express this phenomenon with an observation operator $\\mathcal{P}_{\\mathbf{\\Omega}}$ (see above).\n",
    "\n",
    "Simulate a Hi-C protocol by computing the EDM from the spiral coordinate matrix.\n",
    "Then, sparsify the obtained EDM.\n",
    "(This simulates that not all possible interacting regions are revealed.)\n",
    "Retain 50% of the entries.\n",
    "Recall that the EDM is symmetrical; hence, the sparsification must reflect this property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_mat = gram2edm(gram_mat=coord2gram(coord_mat=coord_mat))\n",
    "\n",
    "mask = np.random.randint(low=2, size=ed_mat.shape, dtype=bool)\n",
    "mask = np.triu(mask)\n",
    "mask = mask + mask.T\n",
    "\n",
    "partial_ed_mat = ed_mat.copy()\n",
    "partial_ed_mat[~mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(label=\"EDM\")\n",
    "ax1.imshow(ed_mat)\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "sparsity = mask.sum() / np.prod(mask.shape)\n",
    "ax1.set_title(label=f\"Sparse EDM (sparsity: {sparsity})\")\n",
    "ax1.imshow(partial_ed_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Preparation for the estimation (using PyTorch) of the true 3D structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to estimate the 3D structure of the spiral from the sparsified EDM using an optimization routine from PyTorch.\n",
    "\n",
    "To estimate the 3D structure given a set of observed interactions, we need to find the best point set representation given the set of observed interactions.\n",
    "Hence, as a first step, we need to initialize a point set.\n",
    "\n",
    "Recall that we are working with tensors in PyTorch.\n",
    "\n",
    "> In PyTorch, tensors are multi-dimensional arrays that are the fundamental data structures for representing and working with data.\n",
    "> Tensors in PyTorch are similar to NumPy arrays, but they have the added benefit of being compatible with GPU acceleration, making them a key component for deep learning and neural network computations.\n",
    "\n",
    "> One of the distinguishing features of PyTorch is its automatic differentiation capability, which is built on top of tensors.\n",
    "> PyTorch keeps track of operations performed on tensors and allows you to compute gradients automatically for purposes like training neural networks using backpropagation.\n",
    "\n",
    "Initialize a 3-by-`SPIRAL_N_POINTS` gradient-tracking PyTorch tensor filled with random numbers from a uniform distribution on the interval $[0,1)$.\n",
    "Then, plot the generated point set using [`plotly.express.scatter_3d()`](https://plotly.com/python-api-reference/generated/plotly.express.scatter_3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.manual_seed(seed=42)\n",
    "predicted_coord_mat = torch.rand(size=(3, SPIRAL_N_POINTS), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_coord_mat_np = predicted_coord_mat.detach().numpy()\n",
    "scatter_3d(coord_mat=predicted_coord_mat_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as a preprocessing step, we convert the sparsified EDM into the coordinate format.\n",
    "\n",
    "> The **COO**rdinate fornat is also known as the 'ijv' or 'triplet' format.\n",
    "> It is used for the efficient representation of sparse matrices via three arrays: row indexes, column indexes, data (`data[i]` is the value at `row[i]`, `col[i]`).\n",
    "\n",
    "We later need this representation to extract the relevant values to compute the loss during optimization.\n",
    "Hence, we preemptively already convert the values to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "partial_ed_mat_coo = coo_matrix(partial_ed_mat)\n",
    "\n",
    "partial_ed_mat_row_ids = partial_ed_mat_coo.row\n",
    "partial_ed_mat_col_ids = partial_ed_mat_coo.col\n",
    "partial_ed_mat_values = torch.from_numpy(partial_ed_mat_coo.data).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a PyTorch'd function to convert a coordinate matrix via the Gram matrix into an EDM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point2edm(coord_mat: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert a matrix of coordinates to an Euclidean distance matrix.\"\"\"\n",
    "    gram_mat = coord_mat.T @ coord_mat\n",
    "    diag_vec = torch.diag(gram_mat).reshape(shape=(-1, 1))\n",
    "    ones_vec = torch.ones((coord_mat.shape[1], 1))\n",
    "    ed_mat = diag_vec @ ones_vec.T + ones_vec * diag_vec.T - 2 * gram_mat\n",
    "    return ed_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the above-initialized coordinate matrix (`predicted_coord_mat`).\n",
    "\n",
    "Try [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) and [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) as optimizer and [`torch.nn.functional.mse_loss()`](https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html) as loss function.\n",
    "\n",
    "> Notice the difference in convergence speed between the different optimizers.\n",
    "\n",
    "In each iteration of the optimization process, do the following:\n",
    "\n",
    "1. Reset the gradients of all optimized tensors.\n",
    "2. Compute the EDM from the current (to-be-optimized) coordinate matrix.\n",
    "3. Compute the loss between the COO values of the sparse ground-truth EDM (`partial_ed_mat_values`) and the corresponding values from the current coordinate matrix.\n",
    "4. Initiate the backprop and perform an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[predicted_coord_mat], lr=1e-1)\n",
    "\n",
    "n_iterations = 100\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    predicted_ed_mat = point2edm(coord_mat=predicted_coord_mat)\n",
    "    partial_predicted_ed_mat_values = predicted_ed_mat[\n",
    "        partial_ed_mat_row_ids, partial_ed_mat_col_ids\n",
    "    ]\n",
    "    loss = mse_loss(input=partial_predicted_ed_mat_values, target=partial_ed_mat_values)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Iteration [{(i + 1):5}/{n_iterations:5}] | Loss={loss:8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the optimized point set using [`plotly.express.scatter_3d()`](https://plotly.com/python-api-reference/generated/plotly.express.scatter_3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_coord_mat_np = predicted_coord_mat.detach().numpy()\n",
    "scatter_3d(coord_mat=predicted_coord_mat_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
